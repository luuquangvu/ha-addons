name: Auto bump Home Assistant add-ons on upstream :latest

on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  check-bump-push:
    name: Bump ${{ matrix.addon.name }}
    runs-on: ubuntu-latest
    concurrency:
      group: auto-bump-${{ matrix.addon.name }}
      cancel-in-progress: false
    strategy:
      fail-fast: false
      matrix:
        addon:
          - name: gemini-fastapi
            dir: gemini-fastapi
            upstream: ghcr.io/luuquangvu/gemini-fastapi
            digest_file: .github/upstream-gemini-fastapi.digest
    env:
      ADDON_DIR: ${{ matrix.addon.dir }}
      DIGEST_FILE: ${{ matrix.addon.digest_file }}

    steps:
      - name: Checkout main
        uses: actions/checkout@v6

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y skopeo

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.x"

      - name: Install Python dependencies
        run: pip install PyYAML

      - name: Extract upstream ref and resolve digest
        id: resolve
        run: |
          UPSTREAM="${{ matrix.addon.upstream }}"
          TRACK_REF="${UPSTREAM}:latest"
          echo "Tracking ref: $TRACK_REF"
          echo "track_ref=$TRACK_REF" >> "$GITHUB_OUTPUT"
          echo "image_name=$UPSTREAM" >> "$GITHUB_OUTPUT"

          MANIFEST_FILE="manifest_raw.json"
          if ! skopeo inspect --raw "docker://$TRACK_REF" > "$MANIFEST_FILE"; then
            echo "::error::Failed to fetch manifest for $TRACK_REF"
            exit 1
          fi

          DIGEST=$(skopeo inspect --format '{{.Digest}}' "docker://$TRACK_REF" 2>/dev/null)
          if [ -z "$DIGEST" ] || [ "$DIGEST" = "null" ]; then
            DIGEST=$(sha256sum "$MANIFEST_FILE" | awk '{print "sha256:"$1}')
          fi

          echo "Latest digest: $DIGEST"
          echo "latest_digest=$DIGEST" >> "$GITHUB_OUTPUT"
          echo "manifest_file=$MANIFEST_FILE" >> "$GITHUB_OUTPUT"

          if [ -f "${DIGEST_FILE}" ]; then
            PREV=$(cat "${DIGEST_FILE}")
          else
            PREV=""
          fi
          echo "Previous digest: ${PREV:-<none>}"

          if [ "$PREV" = "$DIGEST" ]; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
            echo "Digest unchanged."
          else
            echo "changed=true" >> "$GITHUB_OUTPUT"
            echo "Digest changed! Proceeding to validation."
          fi

      - name: Validate Architectures and Bump Version
        if: steps.resolve.outputs.changed == 'true'
        env:
          TRACK_REF: ${{ steps.resolve.outputs.track_ref }}
          IMAGE_NAME: ${{ steps.resolve.outputs.image_name }}
          LATEST_DIGEST: ${{ steps.resolve.outputs.latest_digest }}
          MANIFEST_FILE: ${{ steps.resolve.outputs.manifest_file }}
        run: |
          python - <<EOF
          import os
          import json
          import pathlib
          import re
          import sys
          import yaml
          import subprocess
          from datetime import date
          from concurrent.futures import ThreadPoolExecutor
          from functools import partial

          addon_dir = pathlib.Path(os.environ["ADDON_DIR"])
          config_path = addon_dir / "config.yaml"
          digest_file = pathlib.Path(os.environ["DIGEST_FILE"])

          with open(config_path, "r", encoding="utf-8") as f:
              data = yaml.safe_load(f)

          ha_arch_map = {
              "amd64": "linux/amd64",
              "aarch64": "linux/arm64"
          }

          required_archs = data.get("arch", [])
          required_platforms = [ha_arch_map[a] for a in required_archs if a in ha_arch_map]

          manifest_file = os.environ.get("MANIFEST_FILE")
          with open(manifest_file, "r") as f:
              raw_manifest = json.load(f)

          available_platforms = set()
          if "manifests" in raw_manifest:
              for m in raw_manifest["manifests"]:
                  p = m["platform"]
                  available_platforms.add(f"{p['os']}/{p['architecture']}")
                  if "variant" in p:
                       available_platforms.add(f"{p['os']}/{p['architecture']}/{p['variant']}")
          else:
              os_name = raw_manifest.get("os", raw_manifest.get("Os", "linux"))
              arch = raw_manifest.get("architecture", raw_manifest.get("Architecture", "amd64"))
              available_platforms.add(f"{os_name}/{arch}")

          print(f"Required: {required_platforms}")
          print(f"Available: {available_platforms}")

          missing = [p for p in required_platforms if p not in available_platforms]
          if missing:
              print(f"::error::Upstream lacks required platforms: {missing}")
              sys.exit(1)

          print("Architecture check passed.")

          ver = str(data.get("version", "0.0.0"))
          m = re.match(r"^(\d+)\.(\d+)\.(\d+)$", ver)
          if not m:
              print(f"::error::Unsupported version format: {ver}")
              sys.exit(1)

          major, minor, patch = map(int, m.groups())
          new_ver = f"{major}.{minor}.{patch + 1}"
          data["version"] = new_ver

          with open(config_path, "w", encoding="utf-8") as f:
              yaml.safe_dump(data, f, sort_keys=False, allow_unicode=True)

          print(f"Bumped version from {ver} to {new_ver}")

          digest_file.parent.mkdir(parents=True, exist_ok=True)
          digest_file.write_text(os.environ["LATEST_DIGEST"], encoding="utf-8")

          print("Attempting to find a specific tag matching the latest digest...")
          image_name = os.environ.get("IMAGE_NAME")
          target_digest = os.environ.get("LATEST_DIGEST")
          dockerfile_path = addon_dir / "Dockerfile"
          new_tag = None

          def check_tag(tag, image_name):
              try:
                  cmd = ["skopeo", "inspect", "--format", "{{.Digest}}", f"docker://{image_name}:{tag}"]
                  res = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                  if res.returncode == 0:
                      digest = res.stdout.strip()
                      return tag, digest if digest else None
              except subprocess.TimeoutExpired:
                   print(f"Timeout checking tag: {tag}")
              except Exception as e:
                  print(f"Error checking tag {tag}: {e}")
                  pass
              return tag, None

          try:
              res = subprocess.run(["skopeo", "list-tags", f"docker://{image_name}"], capture_output=True, text=True, check=True)
              tags_data = json.loads(res.stdout)
              all_tags = tags_data.get("Tags", [])

              pattern = re.compile(r"^\d{8}-[a-f0-9]+$")
              version_tags = [t for t in all_tags if pattern.match(t)]
              
              version_tags.sort(reverse=True)
              tags_to_check = version_tags[:10]

              print(f"Checking {len(tags_to_check)} tags in parallel...")
              check_func = partial(check_tag, image_name=image_name)
              with ThreadPoolExecutor(max_workers=2) as executor:
                  results = list(executor.map(check_func, tags_to_check))

              for tag, t_digest in results:
                  if t_digest == target_digest:
                      new_tag = tag
                      break
              
              if new_tag:
                  print(f"Found matching version tag: {new_tag}")
                  content = dockerfile_path.read_text(encoding="utf-8")
                  new_content = re.sub(r"^FROM\s+[^\s]+", f"FROM {image_name}:{new_tag}", content, flags=re.MULTILINE)
                  new_content = re.sub(r'(io\.hass\.version=["\'])([^"\']+)(["\'])', rf'\g<1>{new_ver}\g<3>', new_content)
                  
                  dockerfile_path.write_text(new_content, encoding="utf-8")
                  print(f"Updated {dockerfile_path} to use tag {new_tag} and version {new_ver}")
              else:
                  content = dockerfile_path.read_text(encoding="utf-8")
                  new_content = re.sub(r'(io\.hass\.version=["\'])([^"\']+)(["\'])', rf'\1{new_ver}\3', content)
                  if new_content != content:
                      dockerfile_path.write_text(new_content, encoding="utf-8")
                      print(f"Updated {dockerfile_path} with new version {new_ver}")
                  else:
                      print("Dockerfile already up to date.")
          except Exception as e:
              print(f"Error updating Dockerfile: {e}")

          changelog_path = addon_dir / "CHANGELOG.md"
          old_content = ""
          if changelog_path.exists():
              old_content = changelog_path.read_text(encoding="utf-8")

          today = date.today().isoformat()
          clean_digest = target_digest.replace("sha256:", "") if target_digest else ""
          digest_short = f"{clean_digest[:12]}..." if clean_digest else "latest"
          upstream_ver = new_tag if new_tag else digest_short

          new_entry = f"## {new_ver} - {today}\n\n- Update upstream image to {upstream_ver}\n\n"

          if "# Changelog" in old_content:
              parts = old_content.split("\n", 1)
              header = parts[0]
              rest = parts[1] if len(parts) > 1 else ""
              if rest.startswith("\n"):
                  rest = rest[1:]
              final_content = f"{header}\n\n{new_entry}{rest}"
          else:
              final_content = f"# Changelog\n\n{new_entry}{old_content}"

          changelog_path.write_text(final_content, encoding="utf-8")
          print(f"Updated CHANGELOG.md with version {new_ver}")

          EOF

      - name: Lint Home Assistant add-on
        if: steps.resolve.outputs.changed == 'true'
        uses: frenck/action-addon-linter@v2
        with:
          path: ${{ env.ADDON_DIR }}

      - name: Commit and push
        if: steps.resolve.outputs.changed == 'true'
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"

          git add "${ADDON_DIR}/config.yaml" "${ADDON_DIR}/Dockerfile" "${DIGEST_FILE}" "${ADDON_DIR}/CHANGELOG.md"

          if git diff --staged --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          MSG="chore(${{ matrix.addon.name }}): bump version (upstream ${{ steps.resolve.outputs.track_ref }} -> ${{ steps.resolve.outputs.latest_digest }})"
          git commit -m "$MSG"

          git pull --rebase origin main
          git push origin HEAD:main
